# -*- coding: utf-8 -*-
"""scrapping_coursera.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VUrzrnvtBcqlQ6OtaShGTbAuzlsttH9Z
"""

from bs4 import BeautifulSoup
import requests

# importing the required libraries for scrapping purpose.

response = requests.get("https://www.coursera.org/courses")
html_soup = BeautifulSoup(response.content, 'html.parser')

# we have set the url to scrap and using get method we send a request and then using html.parser we parsed the response content with help of scrapping library called beautiful soup.


url = html_soup.find_all(href=True)

#find all the URLs (items in the html where href exists)



def auto_Scrapper(html_tag,course_case):
  for i in range(1,10):
    url = "https://www.coursera.org/courses?page=" +str(i) + "&index=prod_all_products_term_optimization"
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    all_elements = soup.find_all(html_tag)
    for j in range(0,len(all_elements)):
      x = all_elements[j].get_text()
      course_case.append(x)
        
# the function auto_Scrapper is used to get two parameters that is the tag and what to scrap and get the content scrapped.      

def get_Course_Organization(x):
  return x.get_text()

# the function get_Course_Organization is to extract course organization name based on given html element x

def get_Difficulty_Cert_Type_Time(x):
  soup = BeautifulSoup(x, 'html.parser')
  text = soup.find("p").get_text()
  difficulty = text.split(" · ")[0]
  cert_type = text.split(" · ")[1]
  time = text.split(" · ")[2]
  return difficulty, cert_type, time

# the function get_Difficulty_Cert_Type_Time is to extract course difficulty, certificate type and time span

def get_Rating_And_Reviews_Num(x):
  soup = BeautifulSoup(x, 'html.parser')
  elements = soup.find("p")
  rating = elements[0].get_text()
  reviews_num = elements[1].get_text().split(" ")[0][1:]
  return rating, reviews_num

# the function get_Difficulty_Cert_Type_Time is to extract course rating and number of reviews

def get_Students_Enrolled(soup, html_tag, tag_class):
  element = soup.find_all(html_tag, class_ = tag_class)[0]
  soup_e = BeautifulSoup(element, 'html.parser')
  students_enrolled = soup.find("strong")[0].find("span")[0].get_text()
  return students_enrolled

# the function get_Students_Enrolled is to extract # students erolled

def get_Skills(soup, html_tag, tag_class):
  elements = soup.find_all(html_tag, class_ = tag_class)
  skills = []
  for j in range(0, len(elements)):
      x = elements[j].get_text()
      skills.append(x)
  return skills

# the function get_Skills is to extract course skills

def get_Course_Summary(soup, html_tag, tag_class):
  elements = soup.find_all(html_tag, class_ = tag_class)
  course_summary = []
  for x in elements:
    soup_x = BeautifulSoup(x, 'html.parser')
    summary = soup_x.find_all("p")[0].get_text()
    course_summary.append(summary)
  return course_summary

# the function get_Skills is to extract course summary

def get_Course_Description(soup, html_tag, tag_class):
  about_section = soup.find(html_tag, class_ = tag_class)
  soup_about = BeautifulSoup(about_section, 'html.parser')
  paragraphs = soup_about.find_all("p")
  course_description = ''
  for x in paragraphs:
    paragraph = x.get_text() + "\n"
    course_description += paragraph
  return course_description

# the function get_Skills is to extract course description

def get_Students_Enrolled_Skills_Course_Summary_And_Course_Description(x):
  href = x['href']
  course_href = "https://www.coursera.org" + href
  page = requests.get(url)
  soup = BeautifulSoup(page.content, 'html.parser')
  students_enrolled = get_Students_Enrolled(soup, "p", "css-80vnnb")
  skills = get_Skills(soup, "span", "css-18p0rob")
  course_summary = get_Course_Summary(soup, "div", "css-88ryvb")
  course_description = get_Course_Description(soup, "div", "rc-ToggleableContent about-section")
  return students_enrolled, skills, course_summary, course_description

# the function get_Students_Enrolled_Skills_Content_Description_And_Course_Description is to extract 
# # students erolled, skills, "What You'll Learn" section(course summary) and course description

def auto_Scrapper_Class(html_tag,course_case,tag_class):
  for i in range(1,3):
    url = "https://www.coursera.org/courses?page=" +str(i) + "&index=prod_all_products_term_optimization"
    page = requests.get(url)
    soup = BeautifulSoup(page.content, 'html.parser')
    all_elements = soup.find_all(html_tag, class_ = tag_class)
    for x in all_elements:
        if tag_class == 'cds-ProductCard-partnerNames css-dmxkm1 cds-121':
          org_name = get_Course_Organization(x)
          course_case.append(org_name)
        elif tag_class == 'cds-CommonCard-metadata':
          course_difficulty, course_certificate_type, course_time = get_Difficulty_Cert_Type_Time(x)
          course_case[0].append(course_difficulty)
          course_case[1].append(course_certificate_type)
          course_case[2].append(course_time)
        elif tag_class == 'product-reviews':
          rating, review_num = get_Rating_And_Reviews_Num(x)
          course_case[0].append(rating)
          course_case[1].append(review_num)
        elif tag_class == 'cds-CommonCard-titleLink':
          students_enrolled, skills, course_summary, course_description
           = get_Students_Enrolled_Skills_Course_Summary_And_Course_Description(x):
          course_case[0].append(students_enrolled)
          course_case[1].append(skills)
          course_case[2].append(course_summary)
          course_case[3].append(course_description)
       
# the function auto_Scrapper_Class is used to get three parameters that is the tag,what to scrap and get the content scrapped and class it belongs. 

course_title = []
course_organization = []
course_certificate_type = []
course_rating = []
course_reviews_num = []
course_time = []
course_difficulty = []
course_students_enrolled = []
course_skills = []
course_summary = []
course_description = []

# making an empty list so that we can append each of them at the end into a list for making dataframe.


# auto_Scrapper('h3',course_title)
auto_Scrapper_Class('p',course_organization,'cds-ProductCard-partnerNames css-dmxkm1 cds-121')
print(course_organization[:5])
auto_Scrapper_Class('div',[course_difficulty, course_certificate_type, course_time],'cds-CommonCard-metadata')
print(course_difficulty[:5])
print(course_certificate_type[:5])
print(course_time[:5])
auto_Scrapper_Class('div',[course_rating, course_reviews_num],'product-reviews')
print(course_rating[:5])
print(course_reviews_num[:5])
auto_Scrapper_Class('a',[course_students_enrolled, course_skills, course_summary, course_description],'cds-CommonCard-titleLink')
print(course_students_enrolled[:5], course_skills[:5], course_summary[:5], course_description[:5])

# here we are creating the lists of all data required and appending them to list.

import pandas as pd
courses_df = pd.DataFrame(
                        {
                          'course_title': course_title,
                          'course_organization': course_organization,
                          'course_certificate_type': course_certificate_type,
                          'course_time': course_time,
                          'course_rating':course_rating,
                          'course_reviews_num':course_reviews_num,
                           'course_difficulty':course_difficulty,
                           'course_students_enrolled':course_students_enrolled,
                           'course_skills':course_skills,
                           'course_summary':course_summary,
                           'course_description':course_description
                          }
                        )
courses_df = courses_df.sort_values('course_title')

# here we take each lists we generated by scrapping and made a dataframe out of it isung pandas library.


courses_df.to_csv('UCoursera_Courses.csv')

# At end we convert it into a csv file so we can use it for our data analysis part.
